Advanced Usage
==================================

Low Dimensonality
----------------------------------------------------------
See, Gavetti, G. and Levinthal, D. (2000). "Looking Forward and Looking Backward: Cognitive and Experiential Search", *Administrative Science Quarterly*, Vol. 45, pp. 113-137.

Bounded rationality is manifested primarily in the limited or imperfect cognitive representation that actors use to form mental model of their environment. We can simulate the limited cognitive representation of decision elements by using Toybox. In your simulator, contribution vales are assumed to be grounded on the full cognitive representation model unless you provide a transformation function. We will revisit the topic on how to change a randomly assigned contribution values and conduct a simulation in the context of low dimensionality. 

**Definition: full cognitive representation.** :math:`2^{N}` is the number of fitness values (or performance) in a give landscape with maximum dimensionality.

**Definition: low cognitive representation.** Let :math:`\rho = \{e_1,e_2,\dotsc,e_{N_1}\}` in which each element is in the cognitive configuration set, and :math:`N_{1} \leq N`. The binary representation of partial configuration only based on :math:`\rho` is low cognitive representation. If :math:`N_{1} \ll N`, a decision has low dimensionality.

Gavetti and Levinthal (2000) suggest that the number of local peaks decrease as low cognitive representation is fortified. 

..  figure:: gavetti_levinthal_2000.jpg
    :align: center
    
    Gavetti and Levinthal (2000, p. 122; Figure 5)

The above image is captured from the paper written by Gavetti and Levinthal (2000, p. 122). The Toybox simulator can reproduce this result by:

    >>> # Let's assume that we have created a landscape object. For example,...
    >>> land = Landscape(fitness_contribution_matrix = fit)
    >>> bounded_rationality = [0,1,2,3] 
    >>> # Let's assume that the full range of configurations covers [0,1,2,3,4,5,6,7,8,9] (i.e., N = 10).
    >>> # In this case, the agent only have limited cognition power (i.e, :math:`N_{1} = 4`).
    >>> land.compute_all_locations_id(fix_plan = bounded_rationality)
    >>> land.standardize() # optional
    >>> from landscape import count_local_peak
    >>> number_of_peaks = count_local_peak(land, quielty = False)
    
The utility function, "count_local_peak", calculates the number of local peaks. If you want to monitor the process, set *quietly* = False. The default value is True.

..  figure:: low_dimensionality_local_peaks.png
    :align: center
    :width: 700
    
    Number of Local Peaks


We can obtain the above image by setting ten simulations with N=10, K=9, and :math:`N_{1}=9`. The plotted numbers are mean values.
    

Modeling Uncertainty
----------------------------------------------------------

Unertainty refers to the imperfect assessment of the implications of IS design choices. The extent of imperfection may be reduced (or the accurarcy of assessment may be enhanced) over time as systems prototypes are shown to the users and users allowed to interact and experiment with the prototype.

Intuitively, this suggests the ability of agents to accurately perceive the implications of a move on the landscape; the higher the uncertainty, the less accurately an agent is able to predict the performance implications of moving to another point on the landscape. Uncertainty can be regarded as correlated displacements of fitness contributions where the extent of displacement is reduced (or extent of correlation increased) as feedback is gained from users over successive iterations of the simulation process. 

**Uncertainty under Linear Assumption**. Let parameter *uncertainty* :math:`\Phi`, represent the extent of environmental uncertainty factor :math:`\rho` at time :math:`t`. Then the perceived fitness contribution of decision element :math:`d_{i}`, is computed as :math:`(1-\rho) \cdot c_{i} + \rho \cdot \epsilon`. The extent of uncertainty is reduced over time as more and more feedback is obtained from users (i.e., we assume the effect of feedback increases under linear incremental assumption). Therefore, :math:`\Phi_{t} = (1 - {i}/{N}) \cdot \Phi_{0}` where :math:`I` is an indicator set, :math:`i \in I, i=\{ 0,1,2,...,N \}`.

You can find the **linear_uncertainty** function in the **algorithm** module.

    >>> from algorithm import linear_uncertainty
    
If you want to apply different assumption, write a simple algorithm and plugin in it. For example, the following function shows how you can do it.

..  code-block:: python
    :linenos:
    
    import numpy.random as NPRD # for generating numbers from uniform distribution
    import numpy as NP #NumPy package
    
    def linear_uncertainty(uncertainty_base, c_i, tick, total_tick):
        # use the exact names: uncertainty_base, c_i, tick and total_tick
        # c_i is a numpy array object. It contains given contribution values.
        ep = NPRD.rand(c_i.size) # Epsilon vector
        fit_value_uncertain = float(NP.mean(
                  (1 - uncertainty_base) * c_i + uncertainty_base * ep
        ))
        # the return value is the average of contribution effects.
        return fit_value_uncertain

Toybox has a speical Landscape model for implementing different plugin algorithms. You have to use LandscapeAdaptive for observing effects of uncertainty.

    >>> # Assume we have fitness contribution data as "fit".
    >>> from landscape import LandscapeAdaptive
    >>> land = LandscapeAdaptive(fitness_contribution_matrix = fit)

Since the impact of uncertainty is related to the actual process of simulation, we have to consider AdpaterBehavior class. In your implementation, you may put the following codes:

    >>> agent.performance = self.agent_clan.landscape.get_noised_score_of_location_by_id (
            agent.my_id, # current location of the agent
            func = linear_uncertainty, # uncertainty implementation
            uncertainty_base = self.agent_clan.uncertainty_base, # AgentClan defines environmental parameters
            tick = agent.ct, # Current time retrieved from the agent
            total_tick = agent.tick_end) # Total simulation time
    
Note that we use **get_noised_score_of_location_by_id** instead of **get_score_of_location_by_id**. If you want to get the fitness value at a given location without uncertainty noise, use get_score_of_location_by_id. 


Modeling Dynamism
----------------------------------------------------------

Dynamism represents the notation that requirements may change over time, which can be modeled as the landscape undergoing correlated shocks at some point in time during the simulation process (e.g., at regular intervals in case of recurring changes or at a particular point in time in case of a punctuated environmental change). Intuitively, one might think of this as searching across a landscape beset by disasters. 

**Linear Shock**. Similar to the modeling of uncertainty, dynamism can be regarded as correlated displacements of fitness contributions. In other words, once a landscape is created, every :math:`\Delta` periods (for regular environmental change, or at :math:`t = \Delta` for one-time punctuated change), each contribution value :math:`c_{i}` (the performance contribution of a choice on one design parameter) **is replaced by** :math:`(1 - \tau) \cdot c_{i} + \tau \cdot \mu`, where :math:`\mu` is a new draw from the uniform distribution over the unit interval (:math:`\mathbf{U}[0,1]`). Here, :math:`\tau \geq 0` and :math:`\tau \leq 1`, which represents the extent of environmental change. When :math:`\tau \to 0`, then :math:`c_{t}` and :math:`c_{t+1}` after the change are not substantially different. Conversely, when :math:`\tau \to 1`, :math:`c_{t}` is entirely substituted by a new random number from the uniform distribution :math:`\mathbf{U}`.

Like modeling uncertainty, we need to write an algorithm to implement dynamism. Linear Shock is already written in the module, *algorithm*.

    >>> from algorithm import linear_shock
    
Let's create a simple landscape for testing it.

..  code-block:: python
    :linenos:
    
    from landscape import LandscapeAdaptive
    from landscape import construct_influence_matrix_from_list
    from landscape import FitnessContributionTable
    from algorithm import linear_shock
    model_list = [[1,1,0],[1,1,0],[1,0,1]]
    inf = construct_influence_matrix_from_list(model_list)
    fit = FitnessContributionTable(inf)
    land = LandscapeAdaptive(fitness_contribution_matrix=fit)
    land.compute_all_locations_id()
    for i in range(2**3):
        print land.get_score_of_location_by_id(i)
    

The result is:

..  code-block:: python

    0.283134554278
    0.445238909676
    0.0586787574134
    0.220783112811
    0.50716626203
    0.584507602108
    0.648755475652
    0.72609681573

Now, let's shake it!

..  code-block:: python
    :linenos:
    
    land.shocked(linear_shock,shock = 0.5)
    for i in range(2**3):
        print land.get_score_of_location_by_id(i)

You can see the result is quite different from the previous one.

..  code-block:: python
    
    0.430575801073
    0.479868805625
    0.457608585949
    0.506901590501
    0.649040999882
    0.606767768029
    0.564984284789
    0.522711052936

The function, *linear_shock* is programmed as following:

..  code-block:: python
    :linenos:
    
    def linear_shock(contribution_table,shock):
        import numpy.random as NPRD # for generating random numbers (uniform distribution)
        table_dim = contribution_table.shape # get dimensions
        ep = NPRD.rand(table_dim[0],table_dim[1],table_dim[2]) # mu
        new_table = (1 - shock) * contribution_table + shock * ep # new contribution table for replacement
        return new_table

..  note::

    When the function shocked() is called, all the fitness values which are assigned to the landscape are calculated again; therefore, execution time depends on the number of identified fitness values in the landscape. In addition, we assume that the effect of being shocked is instantly reflected. If you need to put delay of shock, manipulate your AdapterPlan implementation.


Modeling the Modularity Structure
----------------------------------------------------------

Modularity in systems components can be achieved when a system can be decomposed into subsystems where interdependecies among components within each subsystem is high, but interdependencies between components across different subsystems is low.

This can readily be modeled using the influence matrix by specifying the interdepency structure among design choice components.

..  math::

    \begin{pmatrix}
        1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
        1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
        1 & 1 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 \\
        0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 \\
        0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1 & 0 \\
        0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 1 & 1
    \end{pmatrix}\\

    
..  centered:: **Modular Structure**


..  math::

    \begin{pmatrix}
        1 & 0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 \\
        0 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 & 0 \\
        0 & 0 & 1 & 0 & 0 & 1 & 1 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 1 \\
        0 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 1 & 0 \\
        0 & 1 & 1 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 1 & 1 & 0 & 1 & 0 & 0 & 0 \\
        0 & 0 & 1 & 0 & 0 & 0 & 0 & 1 & 0 & 1 \\
        1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 \\
        0 & 0 & 0 & 1 & 0 & 0 & 0 & 1 & 0 & 1
    \end{pmatrix}\\

    
..  centered:: **Random Structure**

To implement different structures, create different influence matrix files and use them to create landscapes.

    >>> # for example, let's assume we have two files: modular_inf.txt and random_inf.txt
    >>> from landscape import construct_influence_matrix_from_file # load module
    >>> inf_modular = construct_influence_matrix_from_file('modular_inf.txt',markchr='1')
    >>> from landscape import FitnessContributionTable # load module
    >>> fit_modular = FitnessContributionTable(inf_modular)
    >>> from landscape import LandscapeAdaptive
    >>> land_modular = LandscapeAdaptive(fitness_contribution_matrix = fit_modular)
    >>> #
    >>> inf_random = construct_influence_matrix_from_file('random_inf.txt',markchr='1')
    >>> fit_random = FitnessContributionTable(inf_random)
    >>> land_random = LandscapeAdaptive(fitness_contribution_matrix = fit_random)
    


Team Up (Organizational Structure)
----------------------------------------------------------

Working together is common in business fields. Let's think about requirement engineering (RE) for developing a business software product. RE teams are typically composed of mixture of business domain users and information systems (IS) professionals where business domain users typically possess ample domain knowledge but lack technical knowledge, while the reverse is true for the IS professionals. :) (Of course, there are excepts!)

The composition of RE teams (let's call it "team up") can be modeled by partitioning the design problem (i.e., the N-element vector :math:`\mathbf{d}`) into two subsets :math:`\langle \mathbf{d_{business}}, \mathbf{d_{IS}} \rangle`, where :math:`\mathbf{d_{business}} = \langle d_{1},d_{2}, \cdots , d_{m} \rangle` and :math:`\mathbf{d_{IS}} = \langle d_{m+1}, d_{m+2}, \cdots , d_{N} \rangle`, where :math:`m` represents the relative importance of business decisions in the development project (:math:`0 \leq m \leq N`).

With this setup, the business domain users are responsible for the business decisions; whereas, the IS professionals are responsible for the technical decisions. During search, each department will only consider changes to its own design problems.

    >>> market_evaluation_by_biz_professional = LandscapeAdaptive(fitness_contribution_matrix = fitness_of_real_demand)
    >>> market_evaluation_by_is_professional = LandscapeAdaptive(fitness_contribution_matrix = fitness_of_real_demand)
    >>> re_team = ReTeamClan(
                    market_evaluation_by_biz_professional,
                    market_evaluation_by_is_professional,
                    1,
                    RequirementEngineeringTeam,
                    100)
    >>> # Information processing power is 1 (the third parameter. We will explain it later).
    >>> # Let's assume 100 teams (the last parameter).
    >>> # ReTeamClan is an implementation of agent.AgentClanTeamUp .
    >>> # RequirementEngineeringTeam is an implementation of agent.Agent .
    >>> search_plan = [[0,1,2],[3,4,5,6,7,8,9]] # work partition, not knowldge partition
    >>> knowledge_D = [[0,1,2,3],[3,4,5,6,7,8,9]] # common knowledge (4th element) and distinctive knowledge (others)
    >>> re_team.set_iteration_plan(search_plan) # searching behavior (in this case, how to work in working places)
    
Let's say the first part is about business domain and the second part is about IS domain. In addition, we assume that business professionals work first and then the IS professionals take over. If The business professional finds a better design configuration, IS professionals must look into it. In this example, we assume that the first, second and third configuration elements are related to business domain knowledge; otherwise, about IS domain knowledge. In some cases, there is a common knowledge pool necessary for both parties. What if a big button for 'searching' is presented in a toolbox? What if a colorful animation is shown during idle time? Technically, the answers to those decision choices are beneficial in understanding productivity of the application. At the same time, those can be associated marketing as product differentiation.

    >>> market_evaluation_by_biz_professional.compute_all_locations_id(fix_plan = knowledge_D[0])
    >>> market_evaluation_by_is_professional.compute_all_locations_id(fix_plan = knowledge_D[1])
    
To simulate team behavior, you need to create an implementation class based on landscape.AdapterPlan. As a part of coding, examine the following:

..  code-block:: python
    :linenos:

    from simulator import AdapterPlan
    class RePlan(AdapterPlan):
        def __init__(self, simulator,adapter_behavior,agent_clan,agent,tick_end):
            AdapterPlan.__init__(self,simulator=simulator, adapter_behavior=adapter_behavior, agent_clan=agent_clan, agent=agent, tick_end=tick_end)
            self.market_evaluation_by_biz_professional = agent_clan.landscapeA
            self.market_evaluation_by_is_professional = agent_clan.landscapeB
        def my_profile(cls):
            return "We are the team!"
        profile = classmethod(my_profile)
        # Execution plan
        def run(self):
            team = self.agent # assign one team
            team.tick_end = self.tick_end # let the team know about d-day
            team_behavior = self.adapter_behavior(self.agent_clan,team) # define behavior
            break_marker = False # stop marker
            market_evaluation_by_biz_professional = self.market_evaluation_by_biz_professional
            market_evaluation_by_is_professional = self.market_evaluation_by_is_professional
            ct = 0 # current time
            # endowment
            team.performance = market_evaluation_by_biz_professional.get_score_of_location_by_id(team.my_id) # can be omitted
            team.performance = market_evaluation_by_is_professional.get_score_of_location_by_id(team.my_id)
            team.visited_ids[team.my_id] = 'v' # mark
            self.simulator.write_record(team) # recording
            while 1:
                for turn, work_task in enumerate(team.plans):
                    team.ct = ct
                    if turn < 1:
                        team.team_idx = 0
                    else:
                        team.team_idx = 1
                    team.my_id, team.performance = current_behavior.execute(agent,work_task)
                    ct += 1
                    self.simulator.write_record(team)
                    if ct >= team.tick_end:
                        break_marker = True
                        break
                if break_marker == True:
                    break
    
Modeling Heterogeneity of Incentives and Rewards
----------------------------------------------------------------

The partitioning of the design problem into heterogenous departments brings to the foreground issues of incentives and how it may impact the search process. Departmental incentives relate to the extent to which each department considers the performance of the other department when assessing design alternatives. So, rather than thinking the unweighted average of the fitness contributions, each department will discount the fitness contributions of the other department's design choices.

..  math::

    & F^{'}_{business}(d) = \left( \sum_{i=1}^{m} c_{i} + incent \times \sum_{i=m+1}^{N} c_{i} \right) / N \\
    & F^{'}_{IS}(d) = \left( incent \times \sum_{i=1}^{m} c_{i} + \sum_{i=m+1}^{N} c_{i} \right) / N \\
    
    
where *incent* is a parameter between 0 and 1 that represents the degree to which each department cares about the ramifications of tis design choices on the other department.

**Example**. If :math:`incent=1`, each department is equally concerned with the effects on the other department and is rewarded for overall performance (i.e., the disparate departments are trying to maximize overall value), whereas when :math:`incent \to 0`, each department seeks to prefers design alternatives that maximize its own local value, potentially at the expense of the other department.

Modeling heterogeneity of incentives is related to the way of implementing an uncertainty structure in the NK model. You need to design a function to yield different effects from different cases. Let's assume that two deparments are working in the same organization; namely, they are in the same team (see also, Team Up). In the previous case, we assume randomness; however, modeling heterogeneity is rather deterministic (meanwhile, incentive is fixed). 

You can use algorithm.incentive_structure() or create your own algorithm. Let's examine "incentive_structure()" in detail.

..  code-block:: python
    :linenos:
    
    def incentive_structure(incentive_base, c_i, which_a, which_b, part_idx):
        N = float(len(which_a) + len(which_b)) 
        # which_a and which_b are lists containing decision elements
        # for example, which_a = [0,1,2], which_b = [3,4,5] where N = 6
        assert N > 0, "No incentive at all"
        import numpy as NP
        # 
        sum_of_a = c_i[which_a].sum()
        sum_of_b = c_i[which_b].sum()
        if part_idx < 1: # for business
            F_d = (sum_of_a + incentive_base * sum_of_b) / N
        else: # for IS
            F_d = (incentive_base * sum_of_a) / N
        return F_d

        
As we can notice, when different agent has initiative, different and distorted performance value can be obtained. You can use the *get_noised_score_of_location_id()* function in the *LandscapeAdaptive* class for describing this.

>>> agent.performance = self.agent_clan.landscape.get_noised_score_of_location_by_id (
        agent.my_id, # current location of the agent
        func = incentive_structure, # uncertainty implementation
        incentive_base = self.agent_clan.incentive_base, # AgentClan defines environmental parameters
        which_a = self.agent_clan.incentive_structure_for_business_department,
        which_b = self.agent_clan.incentive_structure_for_is_department,
        part_idx = agent_clan.part_idx)
        