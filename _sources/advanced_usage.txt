Advanced Usage
==================================

Low Dimensonality
----------------------------------------------------------
See, Gavetti, G. and Levinthal, D. (2000). "Looking Forward and Looking Backward: Cognitive and Experiential Search", *Administrative Science Quarterly*, Vol. 45, pp. 113-137.

Bounded rationality is manifested primarily in the limited or imperfect cognitive representation that actors use to form mental model of their environment. We can simulate the limited cognitive representation of decision elements by using Toybox. In your simulator, contribution vales are assumed to be grounded on the full cognitive representation model unless you provide a transformation function. We will revisit the topic on how to change a randomly assigned contribution values and conduct a simulation in the context of low dimensionality. 

**Definition: full cognitive representation.** :math:`2^{N}` is the number of fitness values (or performance) in a give landscape with maximum dimensionality.

**Definition: low cognitive representation.** Let :math:`\rho = \{e_1,e_2,\dotsc,e_{N_1}\}` in which each element is in the cognitive configuration set, and :math:`N_{1} \leq N`. The binary representation of partial configuration only based on :math:`\rho` is low cognitive representation. If :math:`N_{1} \ll N`, a decision has low dimensionality.

Gavetti and Levinthal (2000) suggest that the number of local peaks decrease as low cognitive representation is fortified. 

..  figure:: gavetti_levinthal_2000.jpg
    :align: center
    
    Gavetti and Levinthal (2000, p. 122; Figure 5)

The above image is captured from the paper written by Gavetti and Levinthal (2000, p. 122). The Toybox simulator can reproduce this result by:

    >>> # Let's assume that we have created a landscape object. For example,...
    >>> land = Landscape(fitness_contribution_matrix = fit)
    >>> bounded_rationality = [0,1,2,3] 
    >>> # Let's assume that the full range of configurations covers [0,1,2,3,4,5,6,7,8,9] (i.e., N = 10).
    >>> # In this case, the agent only have limited cognition power (i.e, :math:`N_{1} = 4`).
    >>> land.compute_all_locations_id(fix_plan = bounded_rationality)
    >>> land.standardize() # optional
    >>> from landscape import count_local_peak
    >>> number_of_peaks = count_local_peak(land, quielty = False)
    
The utility function, "count_local_peak", calculates the number of local peaks. If you want to monitor the process, set *quietly* = False. The default value is True.

..  figure:: low_dimensionality_local_peaks.png
    :align: center
    :width: 700
    
    Number of Local Peaks


We can obtain the above image by setting ten simulations with N=10, K=9, and :math:`N_{1}=9`. The plotted numbers are mean values.
    

Modeling Uncertainty
----------------------------------------------------------

Unertainty refers to the imperfect assessment of the implications of IS design choices. The extent of imperfection may be reduced (or the accurarcy of assessment may be enhanced) over time as systems prototypes are shown to the users and users allowed to interact and experiment with the prototype.

Intuitively, this suggests the ability of agents to accurately perceive the implications of a move on the landscape; the higher the uncertainty, the less accurately an agent is able to predict the performance implications of moving to another point on the landscape. Uncertainty can be regarded as correlated displacements of fitness contributions where the extent of displacement is reduced (or extent of correlation increased) as feedback is gained from users over successive iterations of the simulation process. 

**Uncertainty under Linear Assumption**. Let parameter *uncertainty* :math:`\Phi`, represent the extent of environmental uncertainty factor :math:`\rho` at time :math:`t`. Then the perceived fitness contribution of decision element :math:`d_{i}`, is computed as :math:`(1-\rho) \cdot c_{i} + \rho \cdot \epsilon`. The extent of uncertainty is reduced over time as more and more feedback is obtained from users (i.e., we assume the effect of feedback increases under linear incremental assumption). Therefore, :math:`\Phi_{t} = (1 - {i}/{N}) \cdot \Phi_{0}` where :math:`I` is an indicator set, :math:`i \in I, i=\{ 0,1,2,...,N \}`.

You can find the **linear_uncertainty** function in the **algorithm** module.

    >>> from algorithm import linear_uncertainty
    
If you want to apply different assumption, write a simple algorithm and plugin in it. For example, the following function shows how you can do it.

..  code-block:: python
    :linenos:
    
    import numpy.random as NPRD # for generating numbers from uniform distribution
    import numpy as NP #NumPy package
    
    def linear_uncertainty(uncertainty_base, c_i, tick, total_tick):
        # use the exact names: uncertainty_base, c_i, tick and total_tick
        # c_i is a numpy array object. It contains given contribution values.
        ep = NPRD.rand(c_i.size) # Epsilon vector
        fit_value_uncertain = float(NP.mean(
                  (1 - uncertainty_base) * c_i + uncertainty_base * ep
        ))
        # the return value is the average of contribution effects.
        return fit_value_uncertain

Toybox has a speical Landscape model for implementing different plugin algorithms. You have to use LandscapeAdaptive for observing effects of uncertainty.

    >>> # Assume we have fitness contribution data as "fit".
    >>> from landscape import LandscapeAdaptive
    >>> land = LandscapeAdaptive(fitness_contribution_matrix = fit)

Since the impact of uncertainty is related to the actual process of simulation, we have to consider AdpaterBehavior class. In your implementation, you may put the following codes:

    >>> agent.performance = self.agent_clan.landscape.get_noised_score_of_location_by_id (
            agent.my_id, # current location of the agent
            func = linear_uncertainty, # uncertainty implementation
            uncertainty_base = self.agent_clan.uncertainty_base, # AgentClan defines environmental parameters
            tick = agent.ct, # Current time retrieved from the agent
            total_tick = agent.tick_end) # Total simulation time
    
Note that we use **get_noised_score_of_location_by_id** instead of **get_score_of_location_by_id**. If you want to get the fitness value at a given location without uncertainty noise, use get_score_of_location_by_id. 


Modeling Dynamism
----------------------------------------------------------

Dynamism represents the notation that requirements may change over time, which can be modeled as the landscape undergoing correlated shocks at some point in time during the simulation process (e.g., at regular intervals in case of recurring changes or at a particular point in time in case of a punctuated environmental change). Intuitively, one might think of this as searching across a landscape beset by disasters. 

**Linear Shock**. Similar to the modeling of uncertainty, dynamism can be regarded as correlated displacements of fitness contributions. In other words, once a landscape is created, every :math:`\Delta` periods (for regular environmental change, or at :math:`t = \Delta` for one-time punctuated change), each contribution value :math:`c_{i}` (the performance contribution of a choice on one design parameter) **is replaced by** :math:`(1 - \tau) \cdot c_{i} + \tau \cdot \mu`, where :math:`\mu` is a new draw from the uniform distribution over the unit interval (:math:`\mathbf{U}[0,1]`). Here, :math:`\tau \geq 0` and :math:`\tau \leq 1`, which represents the extent of environmental change. When :math:`\tau \to 0`, then :math:`c_{t}` and :math:`c_{t+1}` after the change are not substantially different. Conversely, when :math:`\tau \to 1`, :math:`c_{t}` is entirely substituted by a new random number from the uniform distribution :math:`\mathbf{U}`.

Like modeling uncertainty, we need to write an algorithm to implement dynamism. Linear Shock is already written in the module, *algorithm*.

    >>> from algorithm import linear_shock
    
Let's create a simple landscape for testing it.

..  code-block:: python
    :linenos:
    
    from landscape import LandscapeAdaptive
    from landscape import construct_influence_matrix_from_list
    from landscape import FitnessContributionTable
    from algorithm import linear_shock
    model_list = [[1,1,0],[1,1,0],[1,0,1]]
    inf = construct_influence_matrix_from_list(model_list)
    fit = FitnessContributionTable(inf)
    land = LandscapeAdaptive(fitness_contribution_matrix=fit)
    land.compute_all_locations_id()
    for i in range(2**3):
        print land.get_score_of_location_by_id(i)
    

The result is:

..  code-block:: python

    0.283134554278
    0.445238909676
    0.0586787574134
    0.220783112811
    0.50716626203
    0.584507602108
    0.648755475652
    0.72609681573

Now, let's give shake it!

..  code-block:: python
    :linenos:
    
    land.shocked(linear_shock,shock = 0.5)
    for i in range(2**3):
        print land.get_score_of_location_by_id(i)

You can see the result is quite different from the previous one.

..  code-block:: python
    
    0.430575801073
    0.479868805625
    0.457608585949
    0.506901590501
    0.649040999882
    0.606767768029
    0.564984284789
    0.522711052936

The function, *linear_shock* is programmed as following:

..  code-block:: python
    :linenos:
    
    def linear_shock(contribution_table,shock):
        import numpy.random as NPRD # for generating random numbers (uniform distribution)
        table_dim = contribution_table.shape # get dimensions
        ep = NPRD.rand(table_dim[0],table_dim[1],table_dim[2]) # mu
        new_table = (1 - shock) * contribution_table + shock * ep # new contribution table for replacement
        return new_table

..  note::

    When the function shocked() is called, all the fitness values which are assigned to the landscape are calculated again; therefore, execution time depends on the number of identified fitness values in the landscape. In addition, we assume that the effect of being shocked is instantly reflected. If you need to put delay of shock, manipulate your AdapterPlan implementation.
    
    

    
Team Up (Organizational Structure)
----------------------------------------------------------